ARG INPUT_DOCKER_REGISTRY=andahme

ARG INPUT_JAVA_MAJOR=8

ARG INPUT_SPARK_VERSION=2.4.4


ARG SPARK_ARTIFACT=http://apache.spinellicreations.com/spark/spark-${INPUT_SPARK_VERSION}/spark-${INPUT_SPARK_VERSION}-bin-hadoop2.7.tgz



FROM ${INPUT_DOCKER_REGISTRY}/debian:base AS distribution

ARG SPARK_ARTIFACT

ARG INPUT_SPARK_VERSION


ADD ${SPARK_ARTIFACT} /tmp/spark-${INPUT_SPARK_VERSION}.tar.gz

RUN tar -zxf /tmp/spark-${INPUT_SPARK_VERSION}.tar.gz -C /opt --strip-component=1 \
# Workaround: https://issues.apache.org/jira/browse/SPARK-28921
    --exclude=jars/kubernetes-client-* \
    --exclude=bin/pyspark* --exclude=python \
    --exclude=bin/sparkR* --exclude=R \
    --exclude=bin/*.cmd \
    --exclude=sbin

# Workaround: https://issues.apache.org/jira/browse/SPARK-28921
ADD https://repo1.maven.org/maven2/io/fabric8/kubernetes-client/4.4.2/kubernetes-client-4.4.2.jar /opt/jars

RUN mkdir /opt/logs /opt/work && \
    chmod -R 777 /opt/conf /opt/logs /opt/work



FROM ${INPUT_DOCKER_REGISTRY}/openjdk-jre:${INPUT_JAVA_MAJOR}-base AS base

ARG INPUT_SPARK_VERSION


ENV SPARK_CONF_DIR /etc/spark

ENV SPARK_HOME /opt/spark-${INPUT_SPARK_VERSION}


ENV PATH ${SPARK_HOME}/bin:${PATH}


COPY --from=distribution /opt ${SPARK_HOME}


RUN ln -s ${SPARK_HOME}/conf ${SPARK_CONF_DIR}

